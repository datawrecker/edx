<ol style="max-height: 451px;" id="transcript-captions" class="subtitles" tabindex="0" role="group" aria-label="Activating an item in this group will spool the video to the corresponding time point. To skip transcript, go to previous item."><li tabindex="-1" style="height: 196px;" class="spacing"></li><li class="" tabindex="0" data-start="830" data-index="0">Hello and welcome everybody to lecture video 6.2 on Kalman Filtering.</li><li class="" tabindex="0" data-start="4870" data-index="1">In this video we will introduce the basic linear Kalman Filter, which is a very efficient</li><li class="" tabindex="0" data-start="9940" data-index="2">implementation of the Bayes Filter that we looked at in the previous videos.</li><li class="" tabindex="0" data-start="14929" data-index="3">So as you remember from the previous video we introduced there the Histogram Filter to</li><li class="" tabindex="0" data-start="20400" data-index="4">estimate the position of a robot in 2D. And the Histogram Filter did that by representing</li><li class="" tabindex="0" data-start="28380" data-index="5">the state space by using a grid. And every cell in this grid then stores the probability</li><li class="" tabindex="0" data-start="36630" data-index="6">that the robot is located in this particular cell.</li><li class="" tabindex="0" data-start="42300" data-index="7">Although this is very easy to understand and very easy to implement it has several disadvantages,</li><li class="" tabindex="0" data-start="49300" data-index="8">and the most striking disadvantage is that it is very inefficient.</li><li class="" tabindex="0" data-start="52850" data-index="9">And the reason for that is that we need to discretize the state space of course, and</li><li class="" tabindex="0" data-start="57460" data-index="10">even in a 2 dimensional world we already need quite many cells to represent the state space.</li><li class="" tabindex="0" data-start="68410" data-index="11">So even in 2D with a reasonable resolution you can end up quickly with maybe a grid of</li><li class="" tabindex="0" data-start="74670" data-index="12">100 by 100 or 1000 by 1000. And that needs lots of memory of course but also on the other</li><li class="" tabindex="0" data-start="82220" data-index="13">hand this needs lots of computational power to update the whole grid.</li><li class="" tabindex="0" data-start="87140" data-index="14">While this is still feasible for 2D, and actually occasional used by scientists and robotists,</li><li class="" tabindex="0" data-start="97070" data-index="15">it scales very poorly with higher dimensions.</li><li class="" tabindex="0" data-start="99450" data-index="16">So imagine that you need to estimate 3 degrees of freedom, then the number of cells already</li><li class="" tabindex="0" data-start="106030" data-index="17">grows cubically. And if we would like to estimate a state of</li><li class="" tabindex="0" data-start="110520" data-index="18">a 6 DOF pose in 3D then this grows extremely quickly.</li><li class="" tabindex="0" data-start="118020" data-index="19">And the other problem is, if you want to have a reasonable resolution, say for example you want to know</li><li class="" tabindex="0" data-start="124170" data-index="20">the position of the quadrotor up to a centimeter or so, then you need even for a few meters</li><li class="" tabindex="0" data-start="131640" data-index="21">a hundreds and thousands of cells along every dimension.</li><li class="" tabindex="0" data-start="137959" data-index="22">So the question is: isn't there a way to represent this state more efficiently?</li><li class="" tabindex="0" data-start="142530" data-index="23">And this is now where the Kalman Filter comes in. The Kalman Filter does that by representing</li><li class="" tabindex="0" data-start="149450" data-index="24">the state in a different way, namely using normal distributions. Which means that we</li><li class="" tabindex="0" data-start="155380" data-index="25">have to store much less information, simply the mean and the covariance to represent the state.</li><li class="" tabindex="0" data-start="161620" data-index="26">And the second advantage is that because it represents the state using a continuous random</li><li class="" tabindex="0" data-start="166660" data-index="27">variable it doesn't have this discretization effect of the grid filter.</li><li class="" tabindex="0" data-start="173510" data-index="28">So the interesting thing is that the Kalman Filter has been developed and used for the</li><li class="" tabindex="0" data-start="178099" data-index="29">first time in the late 50s.</li><li class="" tabindex="0" data-start="180840" data-index="30">It was actually developed by the NASA in the Apollo program, so its first application already</li><li class="" tabindex="0" data-start="190140" data-index="31">was aerial or space navigation to estimate the trajectory of the Apollo rockets.</li><li class="" tabindex="0" data-start="199380" data-index="32">And the cool thing is, and this is also why it was capable in the 50s, it is super-efficient</li><li class="" tabindex="0" data-start="206140" data-index="33">because it requires only very few matrix operations and very few numbers even if you have 6 degrees</li><li class="" tabindex="0" data-start="213080" data-index="34">of freedom or 10 or so.</li><li class="" tabindex="0" data-start="216370" data-index="35">And its applications today are very wide, so it is not only used in robotics and space</li><li class="" tabindex="0" data-start="222959" data-index="36">navigation, but also for diverse things such as economics and weather forecasting.</li><li class="" tabindex="0" data-start="231020" data-index="37">So at basis of the Kalman Filter we have the normal distribution to represent the state.</li><li class="" tabindex="0" data-start="237700" data-index="38">I guess most of you will have seen normal distributions before, just to remind you a</li><li class="" tabindex="0" data-start="242480" data-index="39">bit how this looks like.</li><li class="" tabindex="0" data-start="244440" data-index="40">First let's only look at one dimensional normal distributions which are also called univariate</li><li class="" tabindex="0" data-start="252120" data-index="41">normal distributions. Imagine we have a random variable of which we say that it is normally distributed</li><li class="" tabindex="0" data-start="257059" data-index="42">and we write X~N and then the parameters of such a normal distribution are its mean value</li><li class="" tabindex="0" data-start="266969" data-index="43">and its variance. And this variance can also be written as the squared standard deviation</li><li class="" tabindex="0" data-start="274520" data-index="44">and the standard deviation is usually abbreviated with a lower case sigma.</li><li class="" tabindex="0" data-start="281069" data-index="45">And then, we can specify a probability density function for that X takes a particular value</li><li class="" tabindex="0" data-start="289569" data-index="46">and this is then given by this negative exponential, which looks like this bell shape.</li><li class="" tabindex="0" data-start="302059" data-index="47">And now it's interesting to note that the most likely spot always is at the mean of</li><li class="" tabindex="0" data-start="308210" data-index="48">the normal distribution. And the further you go away the less likely the values become.</li><li class="" tabindex="0" data-start="314249" data-index="49">And just for having an intuitive feeling what's this covariance actually means is that within</li><li class="" tabindex="0" data-start="322319" data-index="50">one standard deviation around the mean we already have 68% of the probability mass,</li><li class="" tabindex="0" data-start="329580" data-index="51">and within 3 standard deviations around then mean we already have 99% of the mass.</li><li class="" tabindex="0" data-start="338400" data-index="52">We can extend this easily to multivariate normal distributions. I indicate this here again</li><li class="" tabindex="0" data-start="344300" data-index="53">by bold capital letters, so this X here has multiple dimensions, for example 2 or 3 or</li><li class="" tabindex="0" data-start="353099" data-index="54">6. And then of course also the mean vector needs to be a vector to specify the mean and</li><li class="" tabindex="0" data-start="361339" data-index="55">instead of having the simple variance we now have a so called covariance matrix.</li><li class="" tabindex="0" data-start="367449" data-index="56">And then again, we can specify the probability density function, which looks almost exactly</li><li class="" tabindex="0" data-start="374050" data-index="57">the same, just that we need to use this covariance matrix here and invert it in the exponent.</li><li class="" tabindex="0" data-start="386409" data-index="58">This is now a visualization of how this density looks like in 2D.</li><li class="" tabindex="0" data-start="392599" data-index="59">So here we have a random variable, which has two dimensions x and y. And now the z direction</li><li class="" tabindex="0" data-start="404369" data-index="60">gives the probability density at this location x and y.</li><li class="" tabindex="0" data-start="407830" data-index="61">And you can see that it still has this bell shape, but now the covariance matrix can shape</li><li class="" tabindex="0" data-start="415210" data-index="62">the appearance of this bell.</li><li class="" tabindex="0" data-start="420069" data-index="63">It can be symmetric and a nice around the bell but it can also be stretched in one direction</li><li class="" tabindex="0" data-start="428360" data-index="64">and it can be rotated. And therefore, it also makes sense to look at the</li><li class="" tabindex="0" data-start="434270" data-index="65">probability density function from above because sometimes it's a bit hard to see how this</li><li class="" tabindex="0" data-start="441020" data-index="66">covariance actually looks like in 3D. So if you would move the camera up and then</li><li class="" tabindex="0" data-start="446789" data-index="67">look from the top on to your plot you can visualize it of course with colors, but you</li><li class="" tabindex="0" data-start="452860" data-index="68">can also visualize with so called Isolines at a particular height and then again you</li><li class="" tabindex="0" data-start="458740" data-index="69">can find heights that correspond to certain probability masses inside of them. For example,</li><li class="" tabindex="0" data-start="465969" data-index="70">you can say that everything which is located inside this red ellipse here has a mass of</li><li style="" class="" tabindex="0" data-start="472819" data-index="71">68% for example. But even more common is to have an Isoline of 95% or 99% for example.</li><li class="" tabindex="0" data-start="481800" data-index="72">Now, a few properties of normal distributions, which are important later for the Kalman Filter.</li><li class="" tabindex="0" data-start="489349" data-index="73">So the first good news is that normal distributions behave linearly, so if we have one random</li><li class="" tabindex="0" data-start="496599" data-index="74">variable X that is normal distributed with a mean of µ and a covariance sigma. And we</li><li class="" tabindex="0" data-start="503330" data-index="75">now define a random variable Y that is a linear combination of a matrix A times X plus some</li><li class="" tabindex="0" data-start="512229" data-index="76">offset B. Then we can directly move this coefficients into the normal distribution. So we know then</li><li class="" tabindex="0" data-start="518580" data-index="77">that this Y is normally distributed again with a mean of A times µ plus B, and a covariance</li><li class="" tabindex="0" data-start="529820" data-index="78">of A times Sigma times A transposed.</li><li class="" tabindex="0" data-start="533820" data-index="79">And the other good news is that if you intersect two Gaussians then you obtain again a Gaussian.</li><li class="" tabindex="0" data-start="539630" data-index="80">So you can imagine this as follows, you have two random variables X_1 and X_2 and both</li><li class="" tabindex="0" data-start="543990" data-index="81">of them are normally distributed, but with different parameters.</li><li class="" tabindex="0" data-start="547700" data-index="82">Then you could compute an intersection just by multiplying this to densities together,</li><li class="" tabindex="0" data-start="556400" data-index="83">and if you fill in the values then you see immediately that the result has to be again</li><li class="" tabindex="0" data-start="561960" data-index="84">a normal distribution and the interesting thing is now to look at how the new mean and</li><li class="" tabindex="0" data-start="567680" data-index="85">the covariance is computed. And we can see that the new mean is actually</li><li class="" tabindex="0" data-start="572790" data-index="86">weighted average between the old means weighted by the covariance. So essentially, say for</li><li class="" tabindex="0" data-start="583380" data-index="87">example the second Gaussian here has a very large covariance so it's a very brought and</li><li class="" tabindex="0" data-start="590310" data-index="88">very wide uncertain distribution. For example X_1 is really narrow and has a very small</li><li class="" tabindex="0" data-start="603820" data-index="89">covariance, so the random variable X_1 has much less uncertainty then random variable</li><li class="" tabindex="0" data-start="609200" data-index="90">X_2. Then the result of the intersection will be strongly influenced by µ_1, so by the</li><li class="" tabindex="0" data-start="619040" data-index="91">first random variable because Sigma_2 is large and Sigma_1 is relatively small. So the influence</li><li class="" tabindex="0" data-start="626450" data-index="92">of µ_2 will be relatively limited. And then, we can also compute a new covariance, essentially</li><li class="" tabindex="0" data-start="633800" data-index="93">by adding the inverse of the individual covariances and taking then again the inverse.</li><li class="" tabindex="0" data-start="638710" data-index="94">And this generaly means that the uncertainty shrinks, so the covariance shrinks, which</li><li class="" tabindex="0" data-start="646710" data-index="95">means that if you combine two Gaussians then the result will be narrower and more certain</li><li class="" tabindex="0" data-start="655160" data-index="96">than the original covariances.</li><li class="" tabindex="0" data-start="658980" data-index="97">And now, let's look again how we can define a process model using these normal distributions.</li><li class="" tabindex="0" data-start="669260" data-index="98">We had before this stochastic process, which is also called a Markov chain. So we have</li><li class="" tabindex="0" data-start="676180" data-index="99">the state in the middle, which is now a vector and we have controls u that influence this</li><li class="" tabindex="0" data-start="682760" data-index="100">state and we have sensor observations z that we can compute given the state. Now our goal</li><li class="" tabindex="0" data-start="688540" data-index="101">is to estimate the x here in the middle, the x_t, from the previous state the controls</li><li class="" tabindex="0" data-start="696350" data-index="102">and the observations that we make.</li><li class="" tabindex="0" data-start="701640" data-index="103">Now, the first ides of course is to represent the full state which is also our belief by</li><li class="" tabindex="0" data-start="707760" data-index="104">a Gaussian, so we say this random variable X is normally distributed with a certain mean</li><li class="" tabindex="0" data-start="713300" data-index="105">µ_t and a covariance Sigma_t. And this state now evolves linearly over time for the moment.</li><li class="" tabindex="0" data-start="722620" data-index="106">For the moment we assume we have a linear relationship, which means that the new state</li><li class="" tabindex="0" data-start="728930" data-index="107">is linear combination of the old state. So we multiply a matrix A, the system matrix</li><li class="" tabindex="0" data-start="734790" data-index="108">also called, times the previous state and obtain the new state.</li><li class="" tabindex="0" data-start="739290" data-index="109">But now, as we said we of course also issue controls and we furthermore assume now that</li><li class="" tabindex="0" data-start="745060" data-index="110">these controls influence our state, so we have a second matrix B called the control</li><li class="" tabindex="0" data-start="751600" data-index="111">matrix that says how this issued control is influencing our new state.</li><li class="" tabindex="0" data-start="763000" data-index="112">And then of course we always assume that there is some noise in our system. For example,</li><li class="" tabindex="0" data-start="769440" data-index="113">because the quadrotor shakes slightly or because there are other disturbances like wind that</li><li class="" tabindex="0" data-start="775560" data-index="114">we cannot model well and so we have to assume that there is a third term epsilon that is</li><li class="" tabindex="0" data-start="783750" data-index="115">our noise. And this noise is again normally distributed</li><li class="" tabindex="0" data-start="788990" data-index="116">around zero, so it is a so called zero-mean noise with a covariance of Q.</li><li class="" tabindex="0" data-start="797570" data-index="117">And this equation now describes how we model the evolution of our state, so the current</li><li class="" tabindex="0" data-start="803090" data-index="118">state is a linear combination of the old state, our controls and some zero-mean noise.</li><li class="" tabindex="0" data-start="812320" data-index="119">And now, we also want to find a sensor model that is linear. So we say that our sensor</li><li class="" tabindex="0" data-start="821770" data-index="120">observation z_t depends on the current state and is multiplied with a so called observation matrix C.</li><li class="" tabindex="0" data-start="832900" data-index="121">And again, for the observations we assume that they are noisy and this noise is again</li><li class="" tabindex="0" data-start="840680" data-index="122">Gaussian with zero-mean, so we can write now that the following equation that describes</li><li class="" tabindex="0" data-start="846279" data-index="123">our sensor model that the observation linearly depend on our previous state plus some zero-mean</li><li class="" tabindex="0" data-start="853260" data-index="124">noise delta.</li><li class="" tabindex="0" data-start="855110" data-index="125">So, to summarize this the Kalman Filter makes the following two model assumptions on this</li><li class="" tabindex="0" data-start="862730" data-index="126">discrete time stochastic process we assume that the state evolves linearly and is a combination</li><li class="" tabindex="0" data-start="871170" data-index="127">of our previous state, the controls and some system noise and we assume that we have a</li><li class="" tabindex="0" data-start="877190" data-index="128">linear sensor, where the sensor observation z depends linearly on the previous</li><li class="" tabindex="0" data-start="883210" data-index="129">state plus some noise. And important is again that we represent the</li><li class="" tabindex="0" data-start="887720" data-index="130">current state x as a normal distribution and we assume that the noise is normally distributed</li><li class="" tabindex="0" data-start="896690" data-index="131">with zero-mean.</li><li class="" tabindex="0" data-start="899570" data-index="132">So just to specify a few of these dimensions of these variables we assume that the state</li><li class="" tabindex="0" data-start="906740" data-index="133">comes from R^n, so a n-dimensional space. We assume that the controls come from an l-dimensional</li><li class="" tabindex="0" data-start="914340" data-index="134">space. And by no means l does not need to be the same as n.</li><li class="" tabindex="0" data-start="919460" data-index="135">So for example, we could have a 3-dimesnional state or a 5-dimesnional state but only a</li><li class="" tabindex="0" data-start="924300" data-index="136">2-dimesnional control. For example, if you have a car that is driving forward then it</li><li style="" class="" tabindex="0" data-start="930870" data-index="137">has a, even in 2D it would have 3 degrees of freedom, so the state would be 3-dimesnional</li><li style="" class="" tabindex="0" data-start="935750" data-index="138">for x, y, and phi.</li><li style="" class="" tabindex="0" data-start="938750" data-index="139">And we only have two degrees of freedom for controlling, this is than called an under</li><li class="" tabindex="0" data-start="944540" data-index="140">activated system because we can only change the speed of driving and we can change the</li><li class="" tabindex="0" data-start="950050" data-index="141">angle of our steering wheel.</li><li style="" class="" tabindex="0" data-start="953190" data-index="142">And then, we have observations which are k-dimensional and again, these observations do not need</li><li class="" tabindex="0" data-start="958320" data-index="143">to coincide with the dimensionality of our state or our controls. For example, we could</li><li class="" tabindex="0" data-start="963790" data-index="144">have a 3-dimesnional state but a 2-dimesnional observation, GPS for example from which we</li><li class="" tabindex="0" data-start="969620" data-index="145">only get our x and y position.</li><li class="" tabindex="0" data-start="975060" data-index="146">And then, we have the process equation that we've seen before, and this matrix A of course</li><li class="" tabindex="0" data-start="981630" data-index="147">then needs to be an n by n matrix. The matrix B that defines the influence of the controls</li><li class="" tabindex="0" data-start="986810" data-index="148">on to the state is a n times l matrix. And in our measurement equation we have this matrix</li><li class="" tabindex="0" data-start="993420" data-index="149">C, which needs to be a n times k matrix.</li><li class="" tabindex="0" data-start="998880" data-index="150">And as we said, we assume that our belief is Gaussian, in particular we have to make</li><li class="" tabindex="0" data-start="1007070" data-index="151">certain assumptions on our initial belief, so in the first time step our prior belief on</li><li class="" tabindex="0" data-start="1013470" data-index="152">where the robot is and it is of course a Gaussian but we need to specify for that µ_0 and Sigma_0.</li><li class="" tabindex="0" data-start="1023270" data-index="153">And if we are uncertain about where the robot is in the beginning, then we could choose</li><li class="" tabindex="0" data-start="1027099" data-index="154">this µ arbitrarily. For example, initialize it with zero and then set the covariance to</li><li class="" tabindex="0" data-start="1033099" data-index="155">a very large matrix, which just means that we are just extremely uncertain and that we</li><li class="" tabindex="0" data-start="1040349" data-index="156">almost have a flat distribution over the belief space.</li><li class="" tabindex="0" data-start="1045079" data-index="157">And then, given these properties that we have seen before of normal distributions we can</li><li class="" tabindex="0" data-start="1050749" data-index="158">compute the next state, which is again a Gaussian distribution then, just because it evolves</li><li class="" tabindex="0" data-start="1060460" data-index="159">linearly. And we can make use of the linear property of normal distributions and also</li><li class="" tabindex="0" data-start="1069169" data-index="160">the observations are Gaussian because they are similarly just a linear combination.</li><li class="" tabindex="0" data-start="1076869" data-index="161">And now, if we apply this representation to the Bayes Filter we end up with a very efficient algorithm.</li><li class="" tabindex="0" data-start="1085289" data-index="162">So just for reminding you of how the Bayes Filter look like, this is what we had in the</li><li class="" tabindex="0" data-start="1091980" data-index="163">previous videos. The Bayes Filter keeps track of the belief</li><li class="" tabindex="0" data-start="1100059" data-index="164">distribution, of the posterior at time step t over the state.</li><li class="" tabindex="0" data-start="1104610" data-index="165">And it consists of two steps, it first integrates the motion u and then it integrates the sensor observations z.</li><li class="" tabindex="0" data-start="1117780" data-index="166">So just to remind you how this looks like. And now we can fill in normal distributions</li><li class="" tabindex="0" data-start="1123539" data-index="167">here first in the first step.</li><li class="" tabindex="0" data-start="1126690" data-index="168">So our process model here is the  irst term for which we can just fill in the normal distribution</li><li class="" tabindex="0" data-start="1136909" data-index="169">with the new mean and the new covariance. And we can fill in our previous belief which</li><li class="" tabindex="0" data-start="1146999" data-index="170">is again just a normal distribution, so both of that actually directly can be filled in</li><li class="" tabindex="0" data-start="1156400" data-index="171">in closed from the definition from the normal distribution.</li><li class="" tabindex="0" data-start="1160580" data-index="172">And then, by multiplying this together if you write this out, which is actually not</li><li class="" tabindex="0" data-start="1164799" data-index="173">too complicated to do, then you end up with a normal distribution again fortunately.</li><li class="" tabindex="0" data-start="1170999" data-index="174">And this normal distribution then just has again a new mean and a new covariance that</li><li class="" tabindex="0" data-start="1179070" data-index="175">can be computed from the matrices A, B, and Q.</li><li class="" tabindex="0" data-start="1184119" data-index="176">And this new belief, belief bar as we call it because it's just a temporarily belief,</li><li class="" tabindex="0" data-start="1191600" data-index="177">is then represented with a Gaussian µ bar and Sigma bar.</li><li class="" tabindex="0" data-start="1198179" data-index="178">And then, we come to the second step of the Bayes Filter, where we need to apply the sensor model.</li><li class="" tabindex="0" data-start="1203700" data-index="179">This step looks as follows, so we have this normalization constant that we ignore for</li><li class="" tabindex="0" data-start="1208070" data-index="180">a moment. We fill in the normal distribution as we had</li><li class="" tabindex="0" data-start="1214759" data-index="181">it and our previous belief. And if you multiply these two together, this</li><li class="" tabindex="0" data-start="1218950" data-index="182">is a bit trickier to derive, you end up again with a normal distribution which consists</li><li class="" tabindex="0" data-start="1227100" data-index="183">of a new mean and a new covariance. And now, the new mean is essentially the old</li><li class="" tabindex="0" data-start="1235249" data-index="184">mean or the µ bar plus matrix K, which is called the Kalman Gain at that we look at</li><li class="" tabindex="0" data-start="1242639" data-index="185">in a second, times our observation minus the predicted observation C µ bar.</li><li class="" tabindex="0" data-start="1250519" data-index="186">So it is important to realize here that what the Kalman Filter actually is doing it blends</li><li class="" tabindex="0" data-start="1257239" data-index="187">our previous estimate µ bar and the discrepancy between our sensor observation and our prediction.</li><li class="" tabindex="0" data-start="1266899" data-index="188">And the degree to which we belief our sensor observation is determined by this Kalman Gain</li><li class="" tabindex="0" data-start="1273999" data-index="189">here, this matrix K, which essentially depends on the ratio between different noise terms.</li><li class="" tabindex="0" data-start="1282660" data-index="190">So for example, the uncertainty that we currently have in our state is this sigmar_bar_t and</li><li class="" tabindex="0" data-start="1296070" data-index="191">the noise or the covariance of our sensor observations is this R. And so essentially</li><li class="" tabindex="0" data-start="1303239" data-index="192">it depends on the ratio between our uncertainty Sigma and the uncertainty of our sensor observation R.</li><li class="" tabindex="0" data-start="1311080" data-index="193">So for example, if we increase our uncertainty of the state Sigma then this Kalman Gain will</li><li class="" tabindex="0" data-start="1320970" data-index="194">get larger and we will put more weight onto our sensor observation z_t - Cµ.</li><li class="" tabindex="0" data-start="1327999" data-index="195">On the other hand, if our sensor noise goes up, if this R gets larger, because it get</li><li class="current" tabindex="0" data-start="1338720" data-index="196">inverted here a larger R means a smaller Kalman Gain. So the more nosily our sensor is, because it has a larger R, the</li><li tabindex="0" data-start="1350779" data-index="197">smaller this Kalman Gain will be. So the less we will trust our sensor reading and the more</li><li tabindex="0" data-start="1355499" data-index="198">we will just stick to our prediction from the model µ bar.</li><li tabindex="0" data-start="1364110" data-index="199">But nevertheless, in the end we obtain a normalized distribution with a new mean µ and a new</li><li tabindex="0" data-start="1371029" data-index="200">covariance Sigma.</li><li tabindex="0" data-start="1373629" data-index="201">So just to summarize now the equations of the Kalman Filter. We have again, like in</li><li tabindex="0" data-start="1379659" data-index="202">the Bayes Filter, the two steps of applying the motion model and the sensor model. Now</li><li tabindex="0" data-start="1385559" data-index="203">in case of the Kalman Filter the first step where we apply the motion model is also called</li><li tabindex="0" data-start="1390279" data-index="204">the prediction step because we make a prediction of our current state given the controls and</li><li tabindex="0" data-start="1395279" data-index="205">the normal evolution of our system. And the second step is also called the correction</li><li tabindex="0" data-start="1402019" data-index="206">step because we correct the estimate of our current pose given the sensor observation.</li><li tabindex="0" data-start="1411440" data-index="207">And one important aspect to note here again as with the Bayes Filter actually is:</li><li tabindex="0" data-start="1418240" data-index="208">that the prediction and correction step don't have to come alternatingly, so you could have five</li><li tabindex="0" data-start="1424759" data-index="209">prediction steps because you getting the odometry at a much higher frame rate and then one correction</li><li tabindex="0" data-start="1430730" data-index="210">step when you are getting a visual observation.</li><li tabindex="0" data-start="1433399" data-index="211">So these two steps can be executed in any arbitrary order depending on what your sensors give you.</li><li tabindex="0" data-start="1445840" data-index="212">There is of course more to say about the Kalman Filter, in particular, I have omitted all</li><li tabindex="0" data-start="1455679" data-index="213">the intermediate steps in the derivation but in case that you are interested in the derivations,</li><li tabindex="0" data-start="1460830" data-index="214">which are actually not too complicated to understand it's something that you can really</li><li tabindex="0" data-start="1464889" data-index="215">do by hand by yourself, then I would recommend to look at the Probabilistic Robotics book</li><li tabindex="0" data-start="1470009" data-index="216">of Thrun, Fox and Burgard. And in chapter 3 there is the full derivation of the Kalman</li><li tabindex="0" data-start="1477580" data-index="217">Filter containing all intermediate steps that you have to do.</li><li tabindex="0" data-start="1483619" data-index="218">So the good news now on the Kalman Filter is that it is extremely efficient, so it is</li><li tabindex="0" data-start="1487710" data-index="219">polynomial in the measurement dimensionality and state dimensionality. The only costly</li><li tabindex="0" data-start="1492739" data-index="220">thing that we have to do is that we have to invert this expression here, which depends</li><li tabindex="0" data-start="1502820" data-index="221">on the size of our observations and our states, but everything else is just a multiplication</li><li tabindex="0" data-start="1509909" data-index="222">of matrices which is extremely fast to compute.</li><li tabindex="0" data-start="1514539" data-index="223">And the other good thing is that it can be shown that this is actually the optimal solution,</li><li tabindex="0" data-start="1520210" data-index="224">so it is the best estimate that you can get if you have linear Gaussian systems and you</li><li tabindex="0" data-start="1527480" data-index="225">have linear Gaussian sensors.</li><li tabindex="0" data-start="1532080" data-index="226">This is a good approximation actually in most cases. Of course there are situations where it</li><li tabindex="0" data-start="1538340" data-index="227">is not a good approximation, but in most cases it is.</li><li tabindex="0" data-start="1541720" data-index="228">The only problem is that most robotic systems are of course nonlinear. So it is hard to</li><li tabindex="0" data-start="1548450" data-index="229">specify this very simple linear transformation matrix for the state or for the sensor.</li><li tabindex="0" data-start="1558749" data-index="230">Now let's look at how to deal with that nevertheless. So if you have a nonlinear function, instead</li><li tabindex="0" data-start="1566899" data-index="231">of having this linear dependency between the state and the current state we can introduce</li><li tabindex="0" data-start="1571619" data-index="232">a certain arbitrary nonlinear function that just takes the previous state and the control</li><li tabindex="0" data-start="1575590" data-index="233">u as input. And similarly we can define a nonlinear or</li><li tabindex="0" data-start="1580440" data-index="234">an arbitrarily observation or sensor function that given the current state makes a prediction</li><li tabindex="0" data-start="1585980" data-index="235">of our sensor measurement. Then the question is can we somehow use these nonlinear functions</li><li tabindex="0" data-start="1591659" data-index="236">in the Kalman Filter as well.</li><li tabindex="0" data-start="1594139" data-index="237">And in particular, the idea is can we actually linearize these functions, and then, the main</li><li tabindex="0" data-start="1601070" data-index="238">idea is to linearize these functions. And we can do that as follows, imagine we</li><li tabindex="0" data-start="1608359" data-index="239">have these nonlinear function g that we want to use in the Kalman Filter. Then we can just</li><li tabindex="0" data-start="1617450" data-index="240">apply a first order Taylor approximation where we linearize at our current pose estimate</li><li tabindex="0" data-start="1623049" data-index="241">µ at time step t-1. And then, we add the derivative of g with respect to the current</li><li tabindex="0" data-start="1634220" data-index="242">state times the distance of the current state from our linearization point µ. And this</li><li tabindex="0" data-start="1645139" data-index="243">derivative here is also called the Jacobian and it is a matrix. So remember g already</li><li tabindex="0" data-start="1652950" data-index="244">gives us a vector typically if our state is multidimensional and now we differentiate</li><li tabindex="0" data-start="1658909" data-index="245">this with respect to the state again. So we end up with an n by n matrix that we can multiply</li><li tabindex="0" data-start="1669200" data-index="246">with the distance from our linearization point to get this first order Taylor expansion.</li><li class="" tabindex="0" data-start="1675149" data-index="247">The same can be done with the observation function, so here again this h refers to a</li><li class="" tabindex="0" data-start="1681549" data-index="248">nonlinear function that we can approximate by taking the function value at our linearization</li><li class="" tabindex="0" data-start="1689450" data-index="249">point µ bar. And then we add the product of the derivative</li><li class="" tabindex="0" data-start="1694889" data-index="250">of this function h with respect to the state times the difference from our current state</li><li tabindex="0" data-start="1701779" data-index="251">minus our linearization point. And this again gives us a Jacobian now this</li><li tabindex="0" data-start="1708379" data-index="252">is called the observation or the sensor Jacobian capital H that we can multiply with the difference</li><li tabindex="0" data-start="1720420" data-index="253">from our current state and our linearization point to obtain the first order Taylor approximation</li><li tabindex="0" data-start="1728309" data-index="254">of our nonlinear function.</li><li tabindex="0" data-start="1730989" data-index="255">And now we can plug this into the Kalman Filter directly. So we have essentially almost the</li><li tabindex="0" data-start="1737509" data-index="256">same equations as before, just now we use our nonlinear motion function for the prediction</li><li tabindex="0" data-start="1745119" data-index="257">step to determine the µ bar. Then we use this Jacobian G to compute our covariance</li><li tabindex="0" data-start="1757940" data-index="258">based on the previous covariance and by adding this sensor noise.</li><li tabindex="0" data-start="1763769" data-index="259">And then in the correction step we again use directly our observation function h at our</li><li tabindex="0" data-start="1770759" data-index="260">current state estimate to make a prediction of what a sensor probably sees.</li><li tabindex="0" data-start="1777470" data-index="261">And then, this difference is multiplied by the Kalman Gain to update our state estimate</li><li tabindex="0" data-start="1784109" data-index="262">and to shrink the covariance then, to reduce the uncertainty by this sensor update we use</li><li tabindex="0" data-start="1793559" data-index="263">now this matrix H, which is the derivative of our nonlinear sensor function with respect</li><li tabindex="0" data-start="1800139" data-index="264">to our current state.</li><li tabindex="0" data-start="1803720" data-index="265">So to summarize this video. We've introduced the Kalman Filter first for the linear case,</li><li class="" tabindex="0" data-start="1812039" data-index="266">and then, we stated that of course most robotics problems most interesting problems are not</li><li tabindex="0" data-start="1819320" data-index="267">linear. So we've shown a way how to linearize then</li><li tabindex="0" data-start="1822639" data-index="268">the sensor and the motion model and in this case this can then be used in the so called</li><li tabindex="0" data-start="1829559" data-index="269">Extended Kalman Filter to deal with such nonlinear sensor and motion models.</li><li tabindex="0" data-start="1834539" data-index="270">And because this was quite theoretical now the next we will show a very nice example</li><li class="" tabindex="0" data-start="1840729" data-index="271">in 2D that hopefully shade some light on the inner functions of the Kalman Filter and also</li><li tabindex="0" data-start="1846720" data-index="272">give you some intuitive understanding of what the individual matrices mean and in particular</li><li class="" tabindex="0" data-start="1854499" data-index="273">how the choice of this noise variables R and Q influence the estimate of the Kalman Filter.</li><li tabindex="-1" style="height: 196px;" class="spacing"></li></ol>
