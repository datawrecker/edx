<ol style="max-height: 451px;" id="transcript-captions" class="subtitles" tabindex="0" role="group" aria-label="Activating an item in this group will spool the video to the corresponding time point. To skip transcript, go to previous item."><li tabindex="-1" style="height: 205.5px;" class="spacing"></li><li tabindex="0" data-start="799" data-index="0">Hello and welcome everybody back to lecture video 5.3.</li><li tabindex="0" data-start="4210" data-index="1">In this video we will introduce Bayes law and then explain how we can use it to infer</li><li tabindex="0" data-start="11460" data-index="2">the world state from the available data.</li><li tabindex="0" data-start="15570" data-index="3">And in terms of data we actually have two sources that we would like to use to infer</li><li tabindex="0" data-start="20710" data-index="4">the world state, namely first we have sensor measurements</li><li tabindex="0" data-start="24160" data-index="5">that we denote with z and those sensor measurements</li><li tabindex="0" data-start="27119" data-index="6">can for example be GPS observation of our position in the 3D world.</li><li tabindex="0" data-start="32570" data-index="7">But we also have knowledge about our controls that we have send to the motors. And those</li><li tabindex="0" data-start="40550" data-index="8">will be denoted by u.</li><li tabindex="0" data-start="43960" data-index="9">And then, of course we need to model the relationship between these senor measurements and our world state.</li><li tabindex="0" data-start="54000" data-index="10">And for that we already introduced the sensor</li><li tabindex="0" data-start="55980" data-index="11">model that describes the probability between x and z.</li><li tabindex="0" data-start="62480" data-index="12">And our motion model that describes the relationship between our previous world state, the motion</li><li tabindex="0" data-start="68940" data-index="13">command that we issued and our new world state.</li><li tabindex="0" data-start="76170" data-index="14">And now it's important to look closely in which direction we are actually reasoning.</li><li tabindex="0" data-start="82320" data-index="15">If we go from the sensor readings to the world state, so we make observations from the sensor</li><li tabindex="0" data-start="90130" data-index="16">and use that to infer the world state, then this is called diagnostic reasoning.</li><li tabindex="0" data-start="96560" data-index="17">If we however go from the world state, if we assume that we know the world state and</li><li tabindex="0" data-start="101750" data-index="18">try to infer what sensor readings are likely then this is called causal reasoning.</li><li tabindex="0" data-start="107360" data-index="19">Typically, at least in our situation we are interested in diagnostic reasoning. We would</li><li tabindex="0" data-start="113200" data-index="20">like to know where the robot is in the world, given that we make certain GPS or odometry</li><li tabindex="0" data-start="119500" data-index="21">observations.</li><li tabindex="0" data-start="121170" data-index="22">But the problem is that diagnostic models are typically very hard to specify and in</li><li tabindex="0" data-start="130330" data-index="23">contrast causal models are much easier to construct.</li><li tabindex="0" data-start="135310" data-index="24">Because in this way, for a causal probability distribution you can just go from the world</li><li tabindex="0" data-start="140030" data-index="25">state and then make predictions on what the senor is likely to report.</li><li tabindex="0" data-start="147640" data-index="26">And with Bayes rule that we will introduce on the next slides we can use a causal model</li><li tabindex="0" data-start="155870" data-index="27">that's much easier to construct to actually do diagnostic inference.</li><li tabindex="0" data-start="160940" data-index="28">So Bayes rule directly follows from the definition of the conditional probability, remember from</li><li tabindex="0" data-start="166220" data-index="29">the previous video that we can write the joint probability as the product of the conditional</li><li tabindex="0" data-start="174730" data-index="30">probability times the prior.</li><li tabindex="0" data-start="177510" data-index="31">So for example, we can factorize the probability P(x,z) into the conditional probability P(x|z)P(z)</li><li tabindex="0" data-start="187770" data-index="32">and that, of course, because we can reverse the variables equals also the probability P(z|x)P(x).</li><li tabindex="0" data-start="196000" data-index="33">And if we reshuffle these terms then we directly obtain Bayes rule. So there is no magic behind</li><li tabindex="0" data-start="201950" data-index="34">Bayes rule, it's just the definition of conditional probability.</li><li tabindex="0" data-start="206020" data-index="35">And it says then that the probability of x of our world state given z our sensor reading, P(x|z),</li><li tabindex="0" data-start="212420" data-index="36">can be obtained by taking the probaility of P(z|x) which is our causul model, which is easy to compute,</li><li tabindex="0" data-start="222720" data-index="37">times the probability  P(x) divided by the probability P(z).</li><li tabindex="0" data-start="229480" data-index="38">Let's look a little bit closer at those terms and how difficult they are to obtain.</li><li tabindex="0" data-start="236170" data-index="39">As we have said, this causal model P(z|x) is typically easy to construct for a given sensor.</li><li tabindex="0" data-start="244319" data-index="40">P(x) encodes the prior on the world state,</li><li tabindex="0" data-start="249800" data-index="41">so how likely is it that we are in a certain state? That is typically either known from</li><li tabindex="0" data-start="253980" data-index="42">the previous time step or you just assume a certain prior depending on your application.</li><li tabindex="0" data-start="261930" data-index="43">But then, you have a denominator the prior on sensor observations. And that's typically</li><li tabindex="0" data-start="269960" data-index="44">very hard to specify, this term generally says how likely it is to make a certain sensor</li><li tabindex="0" data-start="276529" data-index="45">measurement. And depending on your sensor this is might be unknown. So it is unclear</li><li tabindex="0" data-start="283419" data-index="46">how often you actually see a white pixel for a camera or how often you make</li><li tabindex="0" data-start="288740" data-index="47">a certain distance measurement with an ultrasound sensor. That pretty much also depends on you</li><li tabindex="0" data-start="294860" data-index="48">environment around you, and so it's a bit complicated to find this term.</li><li tabindex="0" data-start="301159" data-index="49">But there is a nice trick actually to get around this. And now, the idea is that we</li><li tabindex="0" data-start="307309" data-index="50">just ignore that for a second. We first compute unnormalized likelihoods that do not necessarily</li><li tabindex="0" data-start="315009" data-index="51">sum to 1. So we compute the likelihood of x given z, L(x|z), just without the denominator.</li><li tabindex="0" data-start="322069" data-index="52">And then in a second step we sum all likelihoods and we know that to turn this distribution L into</li><li tabindex="0" data-start="329520" data-index="53">a proper distribution it has to sum to 1. So we can just divide through the sum overall</li><li tabindex="0" data-start="337669" data-index="54">likelihoods in step 3 then.</li><li tabindex="0" data-start="340439" data-index="55">And this gives us a proper probability distribution of P(x|z).</li><li tabindex="0" data-start="349229" data-index="56">And the same derivation actually for the Bayes rule that we had before also works in the</li><li tabindex="0" data-start="356699" data-index="57">presents of background knowledge.</li><li tabindex="0" data-start="358490" data-index="58">So, if we now assume that we have a certain background knowledge set. Then we can still do the same</li><li tabindex="0" data-start="365559" data-index="59">separation for x and y as before. And that gives us then the Bayes rule with background knowledge.</li><li tabindex="0" data-start="372300" data-index="60">So the only change here is that we always have our variables x and y conditioned additionally on</li><li tabindex="0" data-start="378770" data-index="61">a variable z, which just stays on the right side in all of the expressions.</li><li tabindex="0" data-start="383830" data-index="62">And we will need that in a view slides.</li><li tabindex="0" data-start="386749" data-index="63">So because all of this was quite theoretic so far I thought that we should first look</li><li tabindex="0" data-start="392509" data-index="64">at a simple example to clarify maybe a few things to show you how Bayes rule can be applied</li><li tabindex="0" data-start="398029" data-index="65">in practice.</li><li tabindex="0" data-start="399650" data-index="66">So imagine that we having a quadrotor that is seeking its landing zone. And lets further</li><li tabindex="0" data-start="405550" data-index="67">more assume that this landing zone has been marked with many bright lamps, and furthermore,</li><li tabindex="0" data-start="411029" data-index="68">that the quadrotor has a brightness sensor onboard to detect actually these lamps.</li><li tabindex="0" data-start="417789" data-index="69">For that it might have a special purpose brightness sensor of course, but you can in principle</li><li tabindex="0" data-start="421559" data-index="70">also treat a camera as a sophisticated brightness sensor, just by summing over all pixel intensities.</li><li tabindex="0" data-start="428599" data-index="71">Now the problem in this example, or the reason why this is actually interesting is that there</li><li tabindex="0" data-start="435069" data-index="72">are not only lamps at the landing site, but there are also some other lamps distributed</li><li tabindex="0" data-start="441689" data-index="73">around in the environment. So the robot cannot be 100% sure that when</li><li tabindex="0" data-start="447099" data-index="74">it sees a lamp or when the brightness sensor triggers that it is actually above the landing site.</li><li tabindex="0" data-start="453339" data-index="75">So to formalize this problem now a little bit, assume that we have a binary sensor that</li><li tabindex="0" data-start="461169" data-index="76">gives us a reading either of that it detected brightness bellow it or nor.</li><li tabindex="0" data-start="468809" data-index="77">And furthermore, our world state is also quite simple, we are only interested in this binary</li><li tabindex="0" data-start="474559" data-index="78">variable x. Whether we are at home above the landing site or we are not.</li><li tabindex="0" data-start="481099" data-index="79">And now we can specify a sensor model where we specify the probability of detecting brightness</li><li tabindex="0" data-start="487659" data-index="80">when we are above the landing site. And for that we could for example determine</li><li tabindex="0" data-start="492659" data-index="81">experimentally that the brightness sensor triggers above the landing site at a</li><li tabindex="0" data-start="497060" data-index="82">probability of 60%. And by flying around at other places we might furthermore measure</li><li tabindex="0" data-start="505349" data-index="83">that the brightness sensor also occasionally detects brightness when we are not above the landing site.</li><li tabindex="0" data-start="513948" data-index="84">And this value could be specified to 30%.</li><li tabindex="0" data-start="518480" data-index="85">And as you can see, if you build up a sensor model like this, this is now a causal sensor model</li><li tabindex="0" data-start="524670" data-index="86">because being at home or being above the landing site causes the sensor to trigger or not to trigger,</li><li tabindex="0" data-start="531040" data-index="87">is quite easy to construct or to measure also empirically, we could just fly with the robot or hold</li><li tabindex="0" data-start="537310" data-index="88">the quadrotor above the landing site, and then measure how often it actually detects</li><li tabindex="0" data-start="543660" data-index="89">the brightness.</li><li tabindex="0" data-start="545110" data-index="90">Furthermore, we need to define a prior on our world state, if we don't have any preference,</li><li tabindex="0" data-start="551660" data-index="91">if we are 50-50, so to speak, whether we are above the landing zone or not we could set</li><li tabindex="0" data-start="557600" data-index="92">this probability to 0.5.</li><li tabindex="0" data-start="560319" data-index="93">And now, let's furthermore assume that the robot actually observes light, so z equals bright.</li><li tabindex="0" data-start="566680" data-index="94">And now, we would like to know what the probability</li><li tabindex="0" data-start="569790" data-index="95">is, given the sensor model and our prior that we are actually above the landing site given</li><li tabindex="0" data-start="576790" data-index="96">given that the brightness sensor has triggered.</li><li tabindex="0" data-start="579910" data-index="97">And as you can see from the simple example already, it's not straight forward to tell</li><li tabindex="0" data-start="586410" data-index="98">the result because the sensor model goes in the wrong direction. And now, we need this diagnostic</li><li tabindex="0" data-start="594050" data-index="99">reasoning to determine the world state from our sensor readings.</li><li tabindex="0" data-start="600970" data-index="100">But fortunately, of course we are aware of Bayes rule, so we can use Bayes rule now to reverse our</li><li tabindex="0" data-start="611680" data-index="101">causal knowledge, just by filling in now the variable names</li><li tabindex="0" data-start="618240" data-index="102">in Bayes rule we obtain the equation in the middle. And now the only thing that is new</li><li tabindex="0" data-start="624399" data-index="103">is actually the denominator, where we already filled in the normalization constant which always can be</li><li tabindex="0" data-start="635860" data-index="104">computed just by summing up over all possible values of our world state.</li><li tabindex="0" data-start="644490" data-index="105">And if we then fill in the values and compare it. We find that after making this observation</li><li tabindex="0" data-start="651110" data-index="106">that light was detected bellow the quadrotor,</li><li tabindex="0" data-start="656620" data-index="107">then the probability of being above the landing spot increases from 0.5 to 0.67 which is considerably</li><li tabindex="0" data-start="665199" data-index="108">higher but it might not be confident enough to actually trigger a landing behavior.</li><li tabindex="0" data-start="674209" data-index="109">So now let's suppose that our robot obtains another observation just to verify or to consolidate</li><li tabindex="0" data-start="682740" data-index="110">its hypothesis that it is might be above the landing spot.</li><li tabindex="0" data-start="686959" data-index="111">And this second observation could now come from the same sensor, just taken a view seconds</li><li tabindex="0" data-start="692190" data-index="112">later or it could come from a completely different sensor.</li><li tabindex="0" data-start="695569" data-index="113">And then, the question is: how can we integrate this new information in our probability estimate</li><li tabindex="0" data-start="702970" data-index="114">or in our estimate of the world state?</li><li tabindex="0" data-start="705620" data-index="115">So more generally, how can we actually estimate the probability in which world state we are,</li><li tabindex="0" data-start="710540" data-index="116">given that we made a sequence of observations z_1 to z_n with our sensors?</li><li tabindex="0" data-start="719110" data-index="117">And for that we can now use Bayes formula with background knowledge that we've seen</li><li tabindex="0" data-start="723819" data-index="118">in the previous video. Remember that when we want to apply Bayes rule in a setting where</li><li tabindex="0" data-start="732740" data-index="119">we have background knowledge, then we can just keep this background knowledge always</li><li tabindex="0" data-start="740180" data-index="120">on the right side of the bar.</li><li tabindex="0" data-start="743600" data-index="121">So when we apply this Bayes rule now with background knowledge we obtain this relatively large</li><li tabindex="0" data-start="753459" data-index="122">term in the upper right. And now let's first look at the data likelihood</li><li tabindex="0" data-start="760199" data-index="123">that we would now have to evaluate. So this says that we need the likelihood of making</li><li tabindex="0" data-start="765589" data-index="124">a sensor observation z_n given the world state and the values of all our other sensors.</li><li tabindex="0" data-start="772600" data-index="125">And this probability or this likelihood might not be easy to construct because for that</li><li tabindex="0" data-start="777569" data-index="126">we would have to know how all the individual  sensors interact with each other. And how</li><li tabindex="0" data-start="782209" data-index="127">they interact with the world state and that is not easy to specify.</li><li tabindex="0" data-start="786470" data-index="128">But we can make a reasonable assumption here, which is the so called Markov assumption.</li><li tabindex="0" data-start="792670" data-index="129">And the Markov assumption says that the sensor measurement at time step n is independent</li><li tabindex="0" data-start="799350" data-index="130">of all previous sensor measurements as long as we know the world state x.</li><li tabindex="0" data-start="806279" data-index="131">So it doesn't matter at all what all the other sensors measure as long we know what the world</li><li tabindex="0" data-start="810980" data-index="132">state is. We can make a prediction using the sensor model what our sensor will tell us.</li><li tabindex="0" data-start="818529" data-index="133">And this now simplifies a little bit the expression from above.</li><li tabindex="0" data-start="824600" data-index="134">We can strip of this whole dependency on z_1 to z_(n-1) by applying the Markov assumption,</li><li tabindex="0" data-start="832689" data-index="135">but still this other two terms still remain and give us a hard time.</li><li tabindex="0" data-start="838259" data-index="136">But then, we remember that we can apply this trick with the law of total probability in</li><li tabindex="0" data-start="842850" data-index="137">the denominator, so instead of computing this prior probability of a certain sensor reading</li><li tabindex="0" data-start="849120" data-index="138">we can just replace it by a normalization constant and then say that we postpone this</li><li tabindex="0" data-start="854149" data-index="139">normalization until the end because we know that this probability distribution over the</li><li tabindex="0" data-start="859490" data-index="140">world state, our posterior probability distribution over the world state, has to sum to 1 at the</li><li tabindex="0" data-start="864769" data-index="141">end because it needs to be a proper probability distribution.</li><li tabindex="0" data-start="869639" data-index="142">And now, we still have one complicated term here on the right side the probability of</li><li tabindex="0" data-start="874290" data-index="143">x given the sensor measurements of z_1 to z_(n-1). But now it becomes apparent that</li><li tabindex="0" data-start="884970" data-index="144">this is actually the same as what we have started in the beginning. Just that we have</li><li tabindex="0" data-start="890129" data-index="145">already removed now the latest sensor observation z_n.</li><li tabindex="0" data-start="896339" data-index="146">So we could just apply again this principle Bayes rule recursively and this gives us then</li><li tabindex="0" data-start="904029" data-index="147">a very neat expression as we see in the last line. So when we apply n times Bayes rule</li><li tabindex="0" data-start="911129" data-index="148">then we obtain n normalization constants, but in principle that doesn't matter to us</li><li tabindex="0" data-start="915189" data-index="149">because we, anyway, normalize then at the very end. And then, we take the product over all the</li><li tabindex="0" data-start="920230" data-index="150">individual sensor models for the i'th sensor and only at the very end we need to multiply</li><li tabindex="0" data-start="929170" data-index="151">with our prior probability of what we thought in which world state we are in the first place.</li><li tabindex="0" data-start="936970" data-index="152">So now let's apply this to our toy example here. Again the quadrotor seeks for the landing</li><li tabindex="0" data-start="943249" data-index="153">zone. It has detected the bright lamps below it but now let's assume that it has a second</li><li tabindex="0" data-start="950379" data-index="154">sensor with which it can actually detect a visual marker, like this letter H for example</li><li tabindex="0" data-start="957999" data-index="155">below the quadrotor, which gives a very strong indication whether or not we are at the landing site.</li><li tabindex="0" data-start="964880" data-index="156">And for this marker again we can specify a causal sensor model.</li><li tabindex="0" data-start="971389" data-index="157">So we can for example say that this sensor gives us a detection in 80% of the cases when</li><li tabindex="0" data-start="978889" data-index="158">we are above the landing site. And it also gives us false-positives at a rate of 10%</li><li tabindex="0" data-start="984740" data-index="159">if we are not above the landing site. And remember from out previous example we computed</li><li tabindex="0" data-start="991259" data-index="160">a likelihood or probability of 67% that we think that we are above the landing site given that</li><li tabindex="0" data-start="998079" data-index="161">we have observed the lights. So now let's assume that the robot does not</li><li tabindex="0" data-start="1002480" data-index="162">observe the visual marker bellow it and we get a second observation Z_2 that equals not marker.</li><li tabindex="0" data-start="1011699" data-index="163">And now the question is, what is the probability of being home now that we have obtained the</li><li tabindex="0" data-start="1018910" data-index="164">second sensor measurement? And now we can either apply this recursive Bayes rule from</li><li tabindex="0" data-start="1024260" data-index="165">the last slide or we can just apply Bayes rule once more and reuse the values that we</li><li tabindex="0" data-start="1029579" data-index="166">have already computed.</li><li tabindex="0" data-start="1031119" data-index="167">So by doing that and filling in the values we now obtain a probability of 31% after we have not observed</li><li tabindex="0" data-start="1040290" data-index="168">this visual marker.</li><li tabindex="0" data-start="1041300" data-index="169">And you can see that this second observation outweighs the first observation by a lot, which mostly</li><li tabindex="0" data-start="1047099" data-index="170">comes from the fact that this sensor  is much more specific which is reflected in</li><li tabindex="0" data-start="1053820" data-index="171">the probabilities stored in the sensor model.</li><li tabindex="0" data-start="1058320" data-index="172">And now, the second part as we said in the beginning or the second source of information</li><li tabindex="0" data-start="1064890" data-index="173">that we have are our actions and controls that we give to the motors. Those actions</li><li tabindex="0" data-start="1070760" data-index="174">of course also lead to changes in the world state, just because for example if we fly forward,</li><li tabindex="0" data-start="1078040" data-index="175">then obviously the position of the quadrotor changes and the position is most likely part</li><li tabindex="0" data-start="1083900" data-index="176">of our world state that we try to model.</li><li tabindex="0" data-start="1086940" data-index="177">But of course, other parts of the world state might also change that are not under our control</li><li tabindex="0" data-start="1091940" data-index="178">for example other agents or other quadrotors might move as well, there might be humans or other</li><li tabindex="0" data-start="1099320" data-index="179">things that are going on that have influence on the world state.</li><li tabindex="0" data-start="1103300" data-index="180">And even if we don't have other agents in the world the world state might change over</li><li tabindex="0" data-start="1108080" data-index="181">time because it has an intrinsic dynamics for example.</li><li tabindex="0" data-start="1117390" data-index="182">And now in any case the question is how can we incorporate the actions, and in particular</li><li tabindex="0" data-start="1122260" data-index="183">those actions that we are aware of, so to speak our own actions that we have send to</li><li tabindex="0" data-start="1127360" data-index="184">the motors.</li><li tabindex="0" data-start="1129740" data-index="185">So the typical actions that a quadrotor does is obviously to change the speed of its motors</li><li tabindex="0" data-start="1134870" data-index="186">which leads to a change in pitch and roll, and thrust, and so on.</li><li tabindex="0" data-start="1141230" data-index="187">But it's also important to know that even then the world state and in particular the</li><li tabindex="0" data-start="1146000" data-index="188">position of the quadrotor changes when the quadrotor does seemingly nothing, just because</li><li tabindex="0" data-start="1150940" data-index="189">the quadrotor is always in motion and so it will always drift and shake even if you see</li><li tabindex="0" data-start="1157160" data-index="190">to do nothing.</li><li tabindex="0" data-start="1158890" data-index="191">The other interesting observation here is that the actions are actually never carried</li><li tabindex="0" data-start="1163210" data-index="192">out with absolute certainty, so even if we specify to fly one meter forward we cannot</li><li tabindex="0" data-start="1172550" data-index="193">be sure that we actually ending up at the position of plus one meter.</li><li tabindex="0" data-start="1178180" data-index="194">So it is important to realize that actions generally lead to an increase of the uncertainty of</li><li tabindex="0" data-start="1185390" data-index="195">the state estimate. While measurements from sensors generally decrease the uncertainty</li><li tabindex="0" data-start="1193020" data-index="196">because we know better and better the more sensor observations we take where we actually are.</li><li tabindex="0" data-start="1199580" data-index="197">So as we said before to model the relationship between the world state and the actions we</li><li tabindex="0" data-start="1207690" data-index="198">need a motion model or an action model.</li><li tabindex="0" data-start="1211490" data-index="199">And this can be specified using conditional probability density functions where the new</li><li tabindex="0" data-start="1218830" data-index="200">state x' depends on our previous state x and the issued control command u.</li><li tabindex="0" data-start="1226690" data-index="201">So to illustrate this here with a simple example, consider the following toy example.</li><li tabindex="0" data-start="1233230" data-index="202">Imagine that we have a quadrotor and it can only execute a single action namely to takeoff. And for</li><li tabindex="0" data-start="1240470" data-index="203">some reasons we are only interested in a very small part of the world state namely whether</li><li tabindex="0" data-start="1244980" data-index="204">the quadrotor is on the ground or in the air.</li><li tabindex="0" data-start="1248550" data-index="205">And then, we can model that using a so called transition diagram as depicted here on the</li><li tabindex="0" data-start="1254910" data-index="206">slide. So the notes here correspond to the different</li><li tabindex="0" data-start="1260020" data-index="207">world states. So we have two notes, ground and air, and we have some arrows in between. Those</li><li tabindex="0" data-start="1266770" data-index="208">arrows indicate the transition probabilities between these states according to a certain</li><li tabindex="0" data-start="1273870" data-index="209">action. So when we are for example located on the</li><li tabindex="0" data-start="1276390" data-index="210">ground and we execute the takeoff command then with a probability of 90% the quadrotor</li><li tabindex="0" data-start="1281610" data-index="211">will actually takeoff but with a probability of 10% it will still stay on the ground. This</li><li tabindex="0" data-start="1287380" data-index="212">could have various reasons. For example, it might not receive this command</li><li tabindex="0" data-start="1292540" data-index="213">because the wireless connection is temporarily blocked or the battery might be empty. But</li><li tabindex="0" data-start="1299330" data-index="214">in principle you can consider all of this as being noise. And different states of the</li><li tabindex="0" data-start="1304130" data-index="215">world might have a different noise behavior in this motion model.</li><li tabindex="0" data-start="1311520" data-index="216">And then, once the quadrotor is in the air it will stay in the air with 99% probability,</li><li tabindex="0" data-start="1316320" data-index="217">but even then occasionally it will end up on the ground again for example because it runs out of battery.</li><li tabindex="0" data-start="1325850" data-index="218">And now, for actually estimating the world state based on the actions that we have issued</li><li tabindex="0" data-start="1334450" data-index="219">we use the following formula. The problem again is of course is that we want to estimate the</li><li tabindex="0" data-start="1339760" data-index="220">probability of the world state, given that we execute a certain command u.</li><li tabindex="0" data-start="1345000" data-index="221">And we cannot read this out from this motion model directly because we don't know what</li><li tabindex="0" data-start="1351690" data-index="222">the previous world state was. But as you know always when we are uncertain about the world</li><li tabindex="0" data-start="1358170" data-index="223">state we can just integrate over all possible world states or sum over all possible world</li><li tabindex="0" data-start="1363880" data-index="224">states x, and then, multiply the motion model with the prior probability with what we thought</li><li tabindex="0" data-start="1370700" data-index="225">that we are in this state.</li><li tabindex="0" data-start="1374800" data-index="226">And of course this applies both to the discrete case as this previous example, as well</li><li tabindex="0" data-start="1381410" data-index="227">to the continuous case when we are dealing with continuous positions in 2D or 3D.</li><li tabindex="0" data-start="1389020" data-index="228">So to illustrate this once more for the takeoff example: imagine that our prior belief</li><li tabindex="0" data-start="1395490" data-index="229">on the robot state is that the robot is located on the ground.</li><li tabindex="0" data-start="1399190" data-index="230">So P(x = ground) is 1, and then, the robot executes a takeoff action once. And then,</li><li tabindex="0" data-start="1408530" data-index="231">we are interested in computing the probability of the robot being still on the ground after</li><li tabindex="0" data-start="1416570" data-index="232">this action.</li><li tabindex="0" data-start="1418100" data-index="233">And we do this by filling in values by applying this formula from before and then filling</li><li tabindex="0" data-start="1424060" data-index="234">in values. And we see, we can confirm now algorithmically that the robot will still</li><li tabindex="0" data-start="1430920" data-index="235">be on the ground with a probability of 10%.</li><li tabindex="0" data-start="1437250" data-index="236">This summarizes this video. We've looked at the Bayes rule, today at the</li><li tabindex="0" data-start="1444190" data-index="237">derivation of the Bayes rule. And then, we have shown with various examples</li><li tabindex="0" data-start="1448360" data-index="238">how we can use the Bayes rule to actually fuse data from multiple sensor observations</li><li tabindex="0" data-start="1453410" data-index="239">into our state estimate. And how we can use the actions and motion</li><li tabindex="0" data-start="1459490" data-index="240">commands that we have issued to update our belief of the current world state.</li><li tabindex="0" data-start="1464730" data-index="241">And we will need both of that next week to introduce the Bayes filter and the Kalman filter.</li><li tabindex="-1" style="height: 196px;" class="spacing"></li></ol>
