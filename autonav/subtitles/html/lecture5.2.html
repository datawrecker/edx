<ol style="max-height: 451px;" id="transcript-captions" class="subtitles" tabindex="0" role="group" aria-label="Activating an item in this group will spool the video to the corresponding time point. To skip transcript, go to previous item."><li tabindex="-1" style="height: 196px;" class="spacing"></li><li tabindex="0" data-start="1120" data-index="0">Hello and welcome everybody to lecture 5.2 in this video we will give a short recap on</li><li tabindex="0" data-start="7040" data-index="1">probability theory. And the reason for that is that I thought that</li><li tabindex="0" data-start="10190" data-index="2">before we go on with the Bayes Filter and the Kalman Filter that it doesn't hurt to briefly</li><li tabindex="0" data-start="15599" data-index="3">review the basics of probability theory, just to make sure that we have all the same background.</li><li tabindex="0" data-start="23000" data-index="4">I actually hope that most of the concepts present in this video will already be familiar</li><li tabindex="0" data-start="29500" data-index="5">to you, but if not then I would really urge you to look at a preliminary course on probability</li><li tabindex="0" data-start="35379" data-index="6">theory before you continue with this course.</li><li tabindex="0" data-start="41149" data-index="7">So the basic idea behind probability theory is that we have a random experiment that can</li><li tabindex="0" data-start="46600" data-index="8">produce a number of possible outcomes. For example, we can role a dice, and then this</li><li tabindex="0" data-start="52350" data-index="9">dice can produce different outcomes from 1 to 6 for example. And then, this space of</li><li tabindex="0" data-start="59079" data-index="10">possible outcomes is called the sample space. And now, we can talk about events that can</li><li tabindex="0" data-start="64530" data-index="11">occur. And in principle an event is an element of the power set of this sample space. So</li><li tabindex="0" data-start="71040" data-index="12">one possible event A could be that we are interested in even numbers, so A would correspond</li><li tabindex="0" data-start="78300" data-index="13">to the subset of 2, 4 and 6. And now we can talk about the probability of this event to</li><li tabindex="0" data-start="86850" data-index="14">happen. This would be denoted by P(A). And in this particular example the probability of this proposition would be 0.5.</li><li tabindex="0" data-start="97900" data-index="15">In general there are 3 axioms behind modern probability theory. The probability of such</li><li tabindex="0" data-start="103900" data-index="16">an event is always a number between 0 and 1. And there is the set of all possible</li><li tabindex="0" data-start="112070" data-index="17">outcomes, which is called omega. And the probability of omega is always 1. Which is an event that</li><li tabindex="0" data-start="120250" data-index="18">always happens no matter what the outcome is of our random experiment.</li><li tabindex="0" data-start="124920" data-index="19">And the probability on the other hand of the empty set of outcomes of course never occurs. </li><li tabindex="0" data-start="135900" data-index="20">So the probability of the empty set is 0.</li><li tabindex="0" data-start="139950" data-index="21">And there is a third axiom that says: if you're interested in the probability of the combination of two events,</li><li tabindex="0" data-start="150000" data-index="22">then this equals the probability of event one P(A) plus the probability of event B minus the intersection between these two events.</li><li tabindex="0" data-start="161799" data-index="23">So it might happen that event A and B have some outcomes in common and if we wouldn't subtract</li><li tabindex="0" data-start="169950" data-index="24">the probability of this intersection, then we would count certain outcomes twice.</li><li tabindex="0" data-start="176290" data-index="25">Now, the next concept is the so called random variable. We start with discrete random variables,</li><li tabindex="0" data-start="187349" data-index="26">which is just denoted by a capital letter say X for example. And a discrete random variable</li><li tabindex="0" data-start="192510" data-index="27">can take only accountable number of values, x_1 to x_n for example.</li><li tabindex="0" data-start="199239" data-index="28">And then the notation P(X = x_i) refers to the probability that this random variable</li><li tabindex="0" data-start="207849" data-index="29">X actually takes a particular value x_i. And then, this function P is called the probability mass function.</li><li tabindex="0" data-start="218300" data-index="30">Now, in most cases actually we are dealing with continuous random variables; for example,</li><li tabindex="0" data-start="224909" data-index="31">because we want to model the position of a robot in 2D or in 3D.</li><li tabindex="0" data-start="230800" data-index="32">And then X would be a continuous random variable. And then, the problem is that we can't really</li><li tabindex="0" data-start="239079" data-index="33">specify anymore the probability that X takes a particular value, say that the robot is exactly</li><li tabindex="0" data-start="245689" data-index="34">at X equals 3. You know the probability for any element of</li><li tabindex="0" data-start="251430" data-index="35">this set would go to 0 actually. So instead of stating the absolute probability of a certain</li><li tabindex="0" data-start="259930" data-index="36">event we are now talking about the density function,</li><li tabindex="0" data-start="265690" data-index="37">which is denoted by a lower case letter p. And the relation between this density and</li><li tabindex="0" data-start="274770" data-index="38">the probability is that when we are looking at an interval in this continuous space for</li><li tabindex="0" data-start="280900" data-index="39">example if x is between a and b, then the probability is equal to the integral over</li><li tabindex="0" data-start="289280" data-index="40">the density of x in this interval.</li><li tabindex="0" data-start="293740" data-index="41">And to understand or to look at this graphically imagine now the robot is driving along a corridor</li><li tabindex="0" data-start="300400" data-index="42">and it has a certain likelihood. It sees a door knob and so it inferred a probability</li><li tabindex="0" data-start="309310" data-index="43">distribution form which it knows that it stands in front of door.</li><li tabindex="0" data-start="314710" data-index="44">And then, this probability density function could look as follows: there are certain peaks</li><li tabindex="0" data-start="322400" data-index="45">in front of doors and then depending on the sensor model and the motion model as you will</li><li tabindex="0" data-start="326900" data-index="46">see later some of these peaks might be stronger than others.</li><li tabindex="0" data-start="334699" data-index="47">The next property of proper probability distribution is that it always sums to 1. The reason for</li><li tabindex="0" data-start="342050" data-index="48">that is that if we look at all possible values that x can take, then we are actually looking</li><li tabindex="0" data-start="350099" data-index="49">at the full set omega and the probability of omega is 1.</li><li tabindex="0" data-start="354210" data-index="50">And so if we marginalize out this variable we have to obtain 1.</li><li tabindex="0" data-start="362789" data-index="51">The same holds also for the continuous case but then we need to integrate over the domain of x.</li><li tabindex="0" data-start="372580" data-index="52">The next concept is the so called joint probability. This reverse to the case where we have</li><li tabindex="0" data-start="377610" data-index="53">2 random variables or more, say X and Y for example that could encode the 2D position</li><li tabindex="0" data-start="384530" data-index="54">of a robot in x and y direction. And then, we can write this as P(X = x and Y = y )</li><li tabindex="0" data-start="397669" data-index="55">And just as a shortened we often then just write a P(x,y) to keep the notation intuitive</li><li tabindex="0" data-start="407550" data-index="56">and understandable. Of course, we always make sure then that the symbol that we use for the values</li><li tabindex="0" data-start="415199" data-index="57">is the same as the symbol for the random variables, so X equals x and then Y equals y in this case.</li><li tabindex="0" data-start="424819" data-index="58">So if X and Y are independent variables, then they don't influence each other. They describe</li><li tabindex="0" data-start="430900" data-index="59">different properties of the world and then this joint probability of X and Y actually</li><li tabindex="0" data-start="440110" data-index="60">corresponds to the individual probabilities of x times the probability y.</li><li tabindex="0" data-start="448340" data-index="61">And now the notion P(x|y) is called conditional probability, which says</li><li tabindex="0" data-start="458389" data-index="62">that if we already know that y takes a particular value, then how does this influence our probability distribution over x.</li><li tabindex="0" data-start="470580" data-index="63">For example, if we throw a dice and this dice can take values between 1 and 6, and a normal</li><li tabindex="0" data-start="478840" data-index="64">dice you know gives you a uniform distribution. And now, say random variable X encodes the value that</li><li tabindex="0" data-start="486080" data-index="65">we are getting from the dice. And now, we could define a second variable Y that is just binary</li><li tabindex="0" data-start="492139" data-index="66">and tells us whether the number that we've thrown is even or uneven.</li><li tabindex="0" data-start="497009" data-index="67">And now if we would know that the number that we have thrown is even for example, then the</li><li tabindex="0" data-start="503379" data-index="68">probability distribution over X is of course not uniform anymore, but the likelihood of</li><li tabindex="0" data-start="509419" data-index="69">even number then is 1/3 and the probability of uneven numbers is 0, given that we know that</li><li tabindex="0" data-start="516200" data-index="70">the number has to be even.</li><li tabindex="0" data-start="518860" data-index="71">And then, mathematically speaking this corresponds to the following equation,</li><li tabindex="0" data-start="525709" data-index="72">so the conditional probability P(x|y)P(y) equals exactly the joint probability P(x,y) of x and y.</li><li tabindex="0" data-start="539209" data-index="73">And now, if X and Y are independent again, completely independent, so they don't say anything about</li><li tabindex="0" data-start="545300" data-index="74">each other. Then the conditional probability of P(x|y) just equals the probability</li><li tabindex="0" data-start="551690" data-index="75">of x, P(x). Because knowledge of Y does not influence the probability distribution of X.</li><li tabindex="0" data-start="559100" data-index="76">So if we introduce now a third random variable Z we can also talk about the conditional</li><li tabindex="0" data-start="564800" data-index="77">independence between to variables. So for example, if we are looking at the probability</li><li tabindex="0" data-start="568490" data-index="78">distribution over P(x,y|z) then this can corresponds to the product of the conditional probability of P(x|z)P(y|z).</li><li tabindex="0" data-start="587709" data-index="79">Note that this does not imply that X and Y are independent but they are in this case</li><li tabindex="0" data-start="596300" data-index="80">independent as long as we know the value of Z.</li><li tabindex="0" data-start="601380" data-index="81">And this notation now is actually equivalent to the following two things,</li><li tabindex="0" data-start="608630" data-index="82">so it says that: if the knowledge of Y does not change our probability distribution over</li><li tabindex="0" data-start="617610" data-index="83">X and vice versa, then the two variables X and Y are conditional independent given Z.</li><li tabindex="0" data-start="631699" data-index="84">The next concept is called marginalization, if we are looking at a joint probability distribution</li><li tabindex="0" data-start="636670" data-index="85">P(x,y) for example, and we marginalize out Y, which means  that we are no longer interested in the value of Y.</li><li tabindex="0" data-start="645800" data-index="86">And we sum up over all possible values that Y can take, then we obtain the probability distribution just over X.</li><li tabindex="0" data-start="652779" data-index="87">So in this way we can generate the marginalized distribution over X from the joint distribution over X and Y.</li><li tabindex="0" data-start="661279" data-index="88">And again, you have two cases because we could have a discrete random variable for which</li><li tabindex="0" data-start="669899" data-index="89">we would specify the probability mass function or we could have a continuous variable for</li><li tabindex="0" data-start="674990" data-index="90">which we would have to specify the probability density function.</li><li tabindex="0" data-start="678370" data-index="91">And just to illustrate this with an example, imagine that we have the following joint probability</li><li tabindex="0" data-start="684290" data-index="92">distribution between to variables X and Y.</li><li tabindex="0" data-start="688639" data-index="93">And X can take different values x_1 to x_4 and Y can take different values from y_1 to y_4.</li><li tabindex="0" data-start="697300" data-index="94">And then we have a certain joint probability table that we can specify using these 16 different values</li><li tabindex="0" data-start="704400" data-index="95">And now we can marginalize over X for example, to just obtain the probability of Y independent</li><li tabindex="0" data-start="712610" data-index="96">of X, and then, we obtain the row on the right side or we could marginalize out the y's, and</li><li tabindex="0" data-start="721850" data-index="97">then, sum over the probabilities row wise and obtain the last row.</li><li tabindex="0" data-start="730200" data-index="98">So the next important concept is the expected value of a random variable. This means if</li><li tabindex="0" data-start="739269" data-index="99">we roll a dice and we would like to know what is the average value that we are getting out</li><li tabindex="0" data-start="745720" data-index="100">of it? How many steps can we move forward with our figure in a board game for example?</li><li tabindex="0" data-start="751600" data-index="101">Then we would compute the weighted average of all values that a random variable can take</li><li tabindex="0" data-start="759279" data-index="102">on. So for example, if this random variable can take values of x_i, then we would multiply</li><li tabindex="0" data-start="766839" data-index="103">this value with the probability that the random variable actually takes for this value</li><li tabindex="0" data-start="772529" data-index="104">and this actually gives us then the expected value of this random variable.</li><li tabindex="0" data-start="775980" data-index="105">In the continuous case you would have to take the integral over the whole range of values</li><li tabindex="0" data-start="782269" data-index="106">that this random varibale can take on.</li><li tabindex="0" data-start="785829" data-index="107">And it is important to note here that the expectation is actually a linear operator,</li><li tabindex="0" data-start="790079" data-index="108">so if we are looking at an expression E[a X + b] then we can pull</li><li tabindex="0" data-start="799120" data-index="109">out the factor and the offset from the expectation operator and directly compute the expectation</li><li tabindex="0" data-start="804870" data-index="110">of X and then do our computations afterwards.</li><li tabindex="0" data-start="808420" data-index="111">The second important concept is the covariance of a random variable.</li><li tabindex="0" data-start="815670" data-index="112">And it just measures the squared expected deviation from the mean. So it says how large our spread is.</li><li tabindex="0" data-start="822500" data-index="113">In the 1 dimensional case this is also the variance, if we have a multivariate problem</li><li tabindex="0" data-start="830579" data-index="114">with multiple random variables then it is the covariance matrix that you've might have seen before.</li><li tabindex="0" data-start="838420" data-index="115">Now, if we need to estimate this mean or the covariance from observations that we are getting</li><li tabindex="0" data-start="845459" data-index="116">from our sensors for example. Imagine that we have a GPS sensor and that continuously gives</li><li tabindex="0" data-start="851139" data-index="117">us 3D position estimates of our quadrotor, then we would get a sequence of position observations x_1 to x_n</li><li tabindex="0" data-start="860900" data-index="118">from a 3 dimensional space. And then, we would like to know what our average position is. We could just sum over all of these observations</li><li tabindex="0" data-start="870639" data-index="119">and divide by the number of observations that we got and this then called the sample mean.</li><li tabindex="0" data-start="875110" data-index="120">And at the same time we you could compute the sample covariance just by removing the mean from</li><li tabindex="0" data-start="883800" data-index="121">all our observations taking the dot product with the transposed vector and normalizing</li><li tabindex="0" data-start="889899" data-index="122">it by 1 over (n-1). And then, this gives us the spread over the GPS signal</li><li tabindex="0" data-start="895470" data-index="123">for example, which typically is around 3 to 5 meters.</li><li tabindex="0" data-start="900899" data-index="124">So this was a quick recap on probability theory we have introduced random variables,</li><li tabindex="0" data-start="906180" data-index="125">we've looked at joint and conditional probabilities. We've looked at marginalization,</li><li tabindex="0" data-start="911269" data-index="126">and we looked at the sample mean and the sample covariance, and how to compute that from data.</li><li tabindex="0" data-start="917269" data-index="127">And now this forms a very good basis for the next video where we will introduce Bayes law</li><li tabindex="0" data-start="922100" data-index="128">and give some examples.</li><li tabindex="-1" style="height: 215.5px;" class="spacing"></li></ol>
